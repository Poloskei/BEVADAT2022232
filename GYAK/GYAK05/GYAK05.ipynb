{"cells":[{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'seaborn'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[30], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m mode\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"]}],"source":["import numpy as np\n","from typing import Tuple\n","from scipy.stats import mode\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def load_csv(csv_path)->Tuple[np.ndarray,np.ndarray]:\n","    np.random.seed(42)\n","    dataset = np.genfromtxt(csv_path,delimiter=',')\n","    np.random.shuffle(dataset)\n","    x,y = dataset[:,:-1],dataset[:,-1]\n","    return x,y"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["((150, 4), (150,))"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["x,y = load_csv('iris.csv')\n","x.shape,y.shape"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["(array([nan, nan, nan, nan]), array([nan, nan, nan, nan]))"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(x,axis=0),np.var(x,axis=0)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["(array([ 355.46503497, -280.09189189,    2.95      ,   21.74726027]),\n"," array([1.73561968e+07, 1.18405444e+07, 1.51049922e+04, 6.11729208e+04]))"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["np.nanmean(x,axis=0),np.nanvar(x,axis=0)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["x[np.isnan(x)] = 3.5"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["((144, 4), (144,))"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["y = np.delete(y,np.where(x < 0.0)[0],axis=0)\n","y = np.delete(y,np.where(x > 10.0)[0],axis=0)\n","x = np.delete(x,np.where(x < 0.0)[0],axis=0)\n","x = np.delete(x,np.where(x > 10.0)[0],axis=0)\n","x.shape,y.shape"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def train_test_split(features:np.ndarray,\n","                    labels:np.ndarray,\n","                    test_split_ratio:float)->Tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n","    test_size = int(len(features) * test_split_ratio)\n","    train_size = len(features) - test_size\n","    assert len(features) == test_size+train_size,\"Size mismatch!\"\n","\n","    x_train,y_train = features[:train_size,:],labels[:train_size]\n","    x_test,y_test = features[train_size:,:],labels[train_size:]\n","    return x_train,y_train,x_test,y_test"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["x_train,y_train,x_test,y_test = train_test_split(x,y,0.2)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def euclidean(points:np.ndarray,element_of_x:np.ndarray)->np.ndarray:\n","    return np.sqrt(np.sum((points - element_of_x)**2,axis=1))"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["def predict(x_train:np.ndarray,y_train:np.ndarray,x_test:np.ndarray,k:int)->np.ndarray:\n","    labels_pred = []\n","    for x_test_element in x_test:\n","        distances = euclidean(x_train,x_test_element)\n","        distances = np.array(sorted(zip(distances,y_train)))\n","\n","        label_pred = mode(distances[:k,1],keepdims=False).mode\n","        labels_pred.append(label_pred)\n","    return np.array(labels_pred,dtype=np.int64)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 1, 0, 1, 2, 2, 1, 2, 1, 1, 2,\n","       0, 1, 1, 0, 1, 2], dtype=int64)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["y_preds = predict(x_train,y_train,x_test,3)\n","y_preds"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_confusion_matrix(y_test:np.ndarray,y_preds:np.ndarray):\n","    conf_matrix = confusion_matrix(y_test,y_preds)\n","\n","plot_confusion_matrix()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
